# 本文罗列数据岗位可能会被问到的专业问题：

面试时，需要特别注意组织答案（金字塔型）

### 通用技术问题(数据分析人员的语言)：
------------------------------------------------------------------------------------

每个软件可以实现的功能，尤其是tensorflow与pySpark
11. Pyspark的应用场景（被平台逼着用pyspark,但是我并未思考过，为何一定要用pyspark?）

主要是方便地操作spark下的大数据集：
- 方便地操作大数据集进行模型预测，不必担心挤爆机器学习平台（大数据操作优势，相当于普通的python）
- 方便地进行循环迭代操作（python优势，相比于sql）

另外，关于spark:
- spark是一种类似于hadoop的开源集群计算环境，为Python用户提供了pyspark作为API语言，也支持sqld等
- spark是由scala语言实现的
- spark可以更快，原因是分布式数据集、优化迭代工作负载、
   
12. python常见操作，见平时总结
- 数据读入（pd.read_csv,删除drop,重命名列rename，转置.T）
- 创建pandas(dict转化，创建空pandas然后append)
- 数据探索(pandas_profiling, 去重-drop_duplicates,字段类型-dtypes,某列值分布-value_counts,空值判断处理-isna)
- 数据处理（pd.merge, append,pd.concat,排序sort_values, 分组groupby,定义函数并调用）
- 其他处理（时间包datetime,机器学习常用sklearn）

13. Sql常见操作，见平时总结
- 条件筛选（模糊匹配）
- 连接（union, join）
- 截取字段（substr, left, right, position）
- 分组（partition）

------------------------------------------------------------------------------------

21. 异常点outlier举例
outlier分为错误值和因为特殊情景而产生的特殊情况。
- 我平时接触到的异常点，通常指的是业务逻辑异常的值，比如年龄出现负值，或者大于200的值。对应的处理方法就是，较少，则直接删除；多，就要追查原因，然后修正处理。
- 因为特殊情景而产生的特殊情况,比如前段时间因为疫情,车险的出险频率非常低.如果用于定价,那么此段时间的出险频率就不能用.

22. 如何检测处理异常点Outlier
- 现在我会使用逐列查看分布,查看关键的数量关系来判断
- 当然也可以使用算法[isolatedForest](https://www.cnblogs.com/gczr/p/10354646.html)、聚类分析、正态分布分析（超过均值3个方差）来识别，但我日常工作中还没有场景来使用

23. unbalanced data 举例，以及对于模型的影响
比如欺诈场景,欺诈的比例与非欺诈的比例可能是1:1000.
如果模型训练的时候采用准确率这种易受不均衡数据影响的度量,可能

24. 如何处理不均衡数据
分为有3种方法：
- 一种是建模的时候，不再将模型的目标设为简单的准确率，而是使用F值、AUC值、PRC是更好的选择（更改参数eval_metric='auc'）
- 一种是改变分类算法，在传统分类算法上面对不同类别采用不同的加权方式，使得模型更看重少数类(lgb可以设置专门的weight列)
- 一种是改变数据分布，从数据层面使类别更为平衡。下面介绍了改变数据分布的方法。
  - 上采样:小品类复制多份;
  - 下采样:仅从大品类中选取部分样本
  - [SMOTE](https://zhuanlan.zhihu.com/p/44055312):过拟合方法的一种改进,步骤为1 KNN算法取K个近邻 2 取K个近邻的随机插值,构造少数类 

但是在我目前工作场景中,改变不均衡数据的比例并不能让模型在测试集的表现变好

25. 缺失数据处理:
要根据不同原因造成的缺失分别处理:
- 数量较少,直接删除
- 将缺失值作为一个单独的分类
- 填充为某个值,常数或者插值(慎重,插值并非真实值)

------------------------------------------------------------------------------------
31. PSI(population stability index):特征\模型的时间稳定性测定
按照值来划分分组,得到每个分组实际的总体占比与原来的总体占比,然后计算PSI值.

32. 特征筛选的各种方法与优劣
网上可能有3种主流的方法(Filter, wrapper,Embedded),但是我自己总结有以下几种主要的方法:
- 单变量（缺失值、分布异常、分布方差、与目标变量的相关、IV值、PSI）
- 多变量相关性的影响(也就是共线性),可以使用pandas_profiling 来快速返回,但是
- 各种模型算法的重要性排序（决策树，集成算法，如LightGBM, XGboost）
- 递归式消除特征（比较包含此特征的模型结果与剔除该特征的模型结果）
- 主观可解释性也不能忘记

33. 模型特征重要性的方法，与其他方法比的好处与缺点
34. [IV值](https://www.jianshu.com/p/bd350351aa5c)
某特征的IV值衡量的是该特征区分分类问题Y的能力.IV值越大,代表其对于Y的区分能力越强.

35. 连续型变量的分箱处理
分箱的必要性:1好多模型是需要将连续变量进行分箱的,如GLM;2为了使特征鲁棒性更好,免除异常值影响

分箱方式:
- 区间区域等分(间隔距离等分)
- 按照分布等分(分布的分位数)
- 按照决策树输出来确定

36. 特征的归一化处理：决策树类算法不需要，神经网络中的图片识别会做归一化处理,knn算法因为要计算数据距离所以也需要归一化处理
37. 类别型特征处理：xgboost需要数值化（序列编码）+one-hot Encoding独热编码，lightgbm需要数值化（序列编码）
38. 特征组合与降维：没有涉及。为什么我没有涉及？
  - 从模型的可解释性考虑,组合后的特征解释性差
  - 还没有进行这方面的尝试（PCA， LDA）

------------------------------------------------------------------------------------
41. L1正则化与L2正则化,及其区别
葫芦书在164页给出了解释。

简单理解,就是在损失函数后分别添加L1范数(绝对值和)和L2范数(平方和).
L1范数更容易出现稀疏解,用于特征筛选;L2范数更容易防止过拟合,用于模型训练.
可见[网址](https://www.jianshu.com/p/76368eba9c90)

42. 偏差与方差的定义与区别
葫芦书给出了专门的解释。

- 偏差是模型结果均值与真实值的偏离程度；方差是模型结果与真实值的偏离程度的平方差。
- 很明显，bagging可以降低方差，boosting可以降低偏差。

43. A/B testing的应用场景\步骤、最主要的作用
模型上线/策略上线时使用。因为在历史数据上的计算结果与真实实时环境可能存在不同，因此需要继续监控上线效果。

44. A/B testing如何确定样本量
不知道。在专门网站可以计算

45. 蒙特卡洛模拟的方法与应用
蒙特卡洛模拟本质上是对随机现象的模拟。方法如下：
- 常用的情况是历史数据较少，这时会基于历史情况，随机抽样模拟10k个可能出现的情况。比如历史中N个数字，那么直接复制到10k的量，然后随机排序
- 还有函数变换法。历史数据较多，可以推断出概率分布情况，然后产生均匀分布的随机数，然后倒推出符合该分布的随机数。

46. 评分卡（规则引擎）的大体步骤

47. 评分卡（规则引擎）几个关键的问题：
- 特征分箱,且计算woe
- 逻辑回归模型得到概率
- 概率转化为分数
   - 需要定义
- 如何将分数应用于业务（确定threshold）
   - 通过lift曲线看坏人在业务中的占比
   - 通过逻辑回归模型的KS曲线来判断阈值，然后转化为对应的分数

48. 过拟合的判断与处理
如何判断？
 - 泛化效果差，在验证集、测试集的表现远远差于训练集
 
处理：
 - 增加训练样本
 - 筛选特征，减少不相关的特征
 - 降低模型的复杂度（调整参数）
 - 损失函数中添加了防止过拟合的正则项，如lightgbm


49. 如何增强机器学习模型的可解释性
解释单个因子的作用
- SHAP
- 关键特征单因子展示

50. 机器学习模型与传统模型相比的好处与缺点
- ML更精确
- ML黑匣子，容易过拟合，模型可解释性差

51. 调参方法(Grid search，贝叶斯优化算法)
52. 分类模型评估指标的定义、优缺点(accuracy,precison,recall,f1, p-r curve; tpr,fpr,roc,auc;ks)，以欺诈场景为例
 - [网址](https://www.6aiq.com/article/1549986548173)有详细的介绍accuracy,precison,recall,f1, p-r curve; tpr,fpr,roc,auc
 - ks的解释可以见[网址](https://www.cnblogs.com/gczr/p/10354646.html)
 
53. 回归模型评估指标
 - R方
 - explained variance score
 - mean absolute error
 - mean squared error

54. 模型评估，除了技术指标，其实最重要的要看对于业务指标的提升效果

55. 决策树:集成算法的基础,基本概念就是不断地分裂节点
- 决策树的分裂点决定依据(不同算法的分裂函数选取不同)
- 决策树的常见类型(ID3,C4.5, CART)
   - 判断结点使用特征的计算标准不同:ID3使用最大信息增益,C4.5使用最大信息增益比,CART使用Gini系数
   - 处理特征的类型不同:ID3处理离散,C4.5和CART处理连续
   - 处理问题不同:ID3和C4.5处理分类问题,CART处理分类和回归问题

56. 逻辑回归:线性回归+sigmoid函数(线性回归应用于分类问题)
- 作为分类问题的算法优点:简单;可解释性好

57. GBDT算法（Gradient Boosting Decision Tree梯度提升决策树）
简单来说，就是基于上轮决策树预测的残差进行迭代的学习。
- boosting算法
- 基学习器是CART决策树
- 每个基学习器的目标是上一轮预测结果与真实结果的残差

GBDT的优点/缺点：
其实优点与缺点都是相对来说的，可以参考下一个问题

58. Xgboost的特点/优点（与GBDT的的联系与区别）
59. lightgbm的特点/优点（与XGBOOST的联系与区别）

|   | gbdt         | xgboost（GBDT的工程实现）       |
|---|--------------|--------------------------|
| 1 | 不存在正则项       | 代价函数中存在正则项               |
| 2 | 代价函数仅使用一阶导数  | 代价函数进行二阶泰勒展开，同时使用一阶和二阶导数 |
| 3 | 使用CART作为基分类器 | 支持多种类型的基分类器              |
| 4 | 每轮迭代时使用全部数据  | 每轮迭代对数据进行采样              |
| 5 | 没有涉及对于缺失值的处理 | 会自动学习对于缺失值的处理策略          |


60. xgboost调参与lightgbm调参步骤

61. 卷积神经网络的损失函数
62. 卷积神经网络的优化器
63. 卷积神经网络的各层
64. 比如，卷积神经网络的池化层
65. 比如，卷积神经网络的全连接层
66. 比如，卷积神经网络的常用激活函数


------------------------------------------------------------------------------------
### 那些我应该会，但是需要补充学习的知识点：
1. 半监督学习
2. 无监督学习（k-means, KNN, ）
3. 知识图谱
4. 网络爬虫
5. 推荐算法
6. 风控策略全流程
7. 文本表示模型
8. Word2Vec
9. NLP
10. 降维
11. 概率图模型
12. RNN

------------------------------------------------------------------------------------
### 项目相关的问题：
1. STAR法则来描述每个项目
2. 我在项目中扮演的角色
3. 项目中的挑战
4. 项目的不足
5. 如果要鉴别信用卡欺诈业务，你会如何做分析，制定策略？
6. 保险定价的时候，如何定义波动性

------------------------------------------------------------------------------------
### 其他面试合作性、学习性、职业规划、性格、工作负责度、给岗位带来的价值的问题
可以见我的豆瓣文章

## Situation&Task
实际业务场景中经常会出现或长或短的文字性描述，如何利用这些文字性描述来形成用于lightGBM的特征呢？
## Action
有几下几种方法：
1. 关键词字典：基于关键词字典，利用正则匹配文本描述中出现的关键词
2. [词袋模型](https://www.cnblogs.com/HuZihu/p/9576794.html)：也就是统计关键词出现的次数。
- 对于含义相近的词语，只保留一个
- 删除掉无意义的词语
3. [tfidf](https://www.cnblogs.com/HuZihu/p/9576794.html)
4. [N-gram](https://zhuanlan.zhihu.com/p/32829048):反映出词在句子中的含义。  

后面几种，都要基于分词和转化为词向量word Embedding。</br>
- 分词
中文分词使用jieba。jieba除了可以自动划分词语，还支持输入自定义字典。</br>
[snownlp](https://github.com/isnowfy/snownlp)也可以用来中文分词，并且可以判断话语的褒贬程度</br>
- 词向量
词向量word-embedding可以使用[gensim](https://radimrehurek.com/gensim/models/word2vec.html).
```python
    from gensim.test.utils import common_texts
    from gensim.models import Word2Vec
    model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)
    model.save("word2vec.model")
```

词向量还可以使用预训练模型ELMo(Embeddings from Language Models),具体的使用说明见[网址](https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/?utm_source=blog&utm_medium=top-pretrained-models-nlp-article)

对于已经处理了word-embedding,将词转化为向量之后，可以应用如下的方法。

5. [sentence2v](https://blog.csdn.net/promisejia/article/details/88364569)总和运用了word2vec加权，PCA去掉共同因素
6. [Bert](https://blog.csdn.net/jiaowoshouzi/article/details/89073944)是Google2018年推出的NLP预训练模型。其中，BERT-Base, Chinese支持中文
7. NLP预训练模型等：网上可以找到[史上最详尽的NLP预训练模型汇总](https://zhuanlan.zhihu.com/p/62760251)
8. LSTM+业务Y标签


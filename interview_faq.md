1. 决策树的损失函数
   $$
   C_a(t) = \sum _{t=1}^{|T|} N_t*H(t) + \alpha*|T|
   $$
   其中
   $$
   H(t) =  -\sum _k {N_{tk}\over N_t}log {N_{tk}\over N_t}
   $$
   

2. 极大似然法去理解，为什么样本中目标变量的先验概率为k/n
   $$
   C_n ^kp^k(1-p)^{(n-k)}
   $$
   

3. 二项分布，伯努利分布，几何分布，多项分布

   伯努利分布：

   二项分布：n次伯努利实验，事件A刚好发生k次，事件发生的次数（x=k）即为二项分布

   几何分布：一直进行伯努利实验，事件A刚好第一次发生，实验的次数，为随机数，服从几何分布

   多项分布：二项分布的，每次实验是两个结果，将两个结果推广到多个结果，就是多项分布

4. 为什么会出现过拟合

   * 在特征张成的空间中，对于概率类型的模型，机器学习的本质，就是把特征空间不断进行切割成小的子空间，通过观察样本落入该子空间中的样本数据，推断落入该子空间的目标变量服从的分布及参数估计，即引入后验知识切分空间，然后对每个子空间进行参数估计
   * 但是因为子空间切的足够小的话，落入该子空间的样本可能非常少，因为目标变量通过样本进行观测，具备随机性，所以在该子空间，用小样本随机试验的结果进行估计，不准确，可能是随机因素造成的，进而造成参数估计误差较大，从而造成过拟合
   * 举个例子，假如是随机抛硬币，正反面个1/2的概率，假定落入某个子空间，刚好有4个观测样本，全都是正面（因为子空间足够多，还是容易出现的），对于新样本，如果落入该子空间，我们模型判断为正的概率为100%，但是实际新样本为正还是1/2概率，总体样本的分布其实并没有变化，还是那枚硬币，总体样本还是服从p=1/2的二项分布，但是模型预测错了，这个就是因为过拟合了
   * 样本分布发生了变化，无论是特征变量的分布发生了变化，还是目标变量的分布发生了变化，只能说模型不适用了，模型预测不准确了，需要进行重新训练，因为特征张成的空间发生了改变，必定原始的空间切割方式也不适用了，或者目标变量分布发生了变化，也就是新数据和样本数据不再独立同分布了，但是归为过拟合不是很准确，因为即使这个没有发生变化，依然会出现过拟合，变量分布发生变化，一般还是需要有个度，实际操作中，经常会拿psi稳定性指标来衡量。

5. 怎么样解决过拟合
   * 在损失函数中加入正则项，降低模型的复杂度，不同模型，依据不同的损失函数，正则项也各不相同
   * 参数中，设定树的深度，叶子节点数量，单个叶子节点的最小样本数量等参数

6. 为什么L1正则会造成部分特征消失，而L2正则只会缩小特征的权重，而不会消失
   * 从代价函数来看，包括经验风险部分，结构性风险部分，也就是误差平方和+正则项范数部分，从两部分函数来看，代价函数的两部分是此消彼长的，在参数空间中，因为L1正则是不规则方形等高线，而误差平方和部分是弧形等高线，假定误差平方和部分不变，若要方形最小化，方形等高线与弧形等高线可能相交在顶点上，在参数表现上，就是特征空间中，某些特征的重要性为0。
   * 如果采用L2范数，那么正则部分，也是弧形等高线，那么两个弧形等高线相交的部分，不太会出现在顶点上面

7. 一般如何筛选特征
   * 通过评估一些指标，比如：特征变量与目标变量的相关性系数，分类问题，可能是iv值的大小，或者通过随机森林，我们进行特征的重要性进行排序，然后按照重要性进行筛选。
   * 实际操作当中，往往计算的特征之间，往往会有相关性，可能相关性比较强的一些变量，可能筛选出来几个，比如不相关的一些特征，因为和其他特征相关性非常弱，可能也进入模型。

8. 一般如何进行模型选择
   * 为什么选择某些模型，

9. 模型调优
   * 参数的网格搜索
   * k折交叉验证

10. 模型评估
   * 准确率，查全率，查准率，tpr，fpr，roc曲线、auc、ks值、F1值，Lift值

11. 模型的可解释性
    * 简单的模型，如：线性回归，逻辑回归，评分卡
    * 复杂的模型，如：shap值

12. 如何处理不均衡数据 分为有3种方法：
    - 一种是建模的时候，不再将模型的目标设为简单的准确率，而是使用不易受到不均衡数据影响的指标，如F值、AUC值、PRC是更好的选择（更改参数eval_metric='auc'）
    - 一种是改变分类算法，在传统分类算法上面对不同类别采用不同的加权方式，使得模型更看重少数类(lgb可以设置专门的weight列)
    - 一种是改变数据分布，从数据层面使类别更为平衡。下面介绍了改变数据分布的方法。
      - 上采样:小品类复制多份;
      - 下采样:仅从大品类中选取部分样本
      - [SMOTE](https://zhuanlan.zhihu.com/p/44055312):过拟合方法的一种改进,步骤为1 KNN算法取K个近邻 2 取K个近邻的随机插值,构造少数类

13. 偏差与方差
    - 偏差是模型结果均值与真实值的偏离程度；反应的是拟合的能力，测试集中偏差大可能是欠拟合
    - 方差是模型结果与真实值的偏离程度的平方差。测试集中方差大可能是过拟合了
    - 很明显，bagging偏差大方差小，boosting偏差小方差大。

14. 需要k折交叉验证

    https://blog.csdn.net/weixin_36103474/article/details/92799657

    1.根本原因：数据有限，单一的把数据都用来做训练模型，容易导致过拟合。（反过来，如果数据足够多，完全可以不使用交叉验证。）较小的k值会导致可用于建模的数据量太小，所以小数据集的交叉验证结果需要格外注意，建议选择较大的k值。
    2.理论上：使用了交叉验证，模型方差“应该”降低了。
    在理想情况下，我们认为k折交叉验证可以 O ( 1 / k ) O(1/k)O(1/k)的效率降低模型方差，从而提高模型的泛化能力。通俗地说，我们期望模型在训练集的多个子数据集上表现良好，要胜过单单在整个训练数据集上表现良好。（注意：但实际上，由于所得到的k折数据之间并非独立而是存在相关性，k折交叉验证到底能降低多少方差还不确定，同时可能会带来偏差上升。）

15. adaboost模型，gbdt模型，xgboost模型，lightgbm模型比较
    * boosting算法，其实是一个加法模型，就是有很多个弱分类器，将这些弱分类器的结果按照一定的权重相加，生成最终的预测结果。
    * adaboost，是1995年，由谁谁谁提出来，两个点：1.不断加强错误分类样本的权重，2.采用指数函数作为损失函数
    * gbdt算法，不能用类似mini batch的方式进行训练，需要对数据进行无数次遍历，为了能让gbdt高效地用上更多的数据，把gbdt转向分布式，就有了

16. 线性超平面
    * 对于分类问题，针对样本集，我们假定样本是线性可分的，机器学习的本质就是找到线性超平面，使得正负样本能够分开
    * 对于回归问题，是输入空间与输出空间，假定存在着一种函数映射（可能是线性，非线性等），机器学习的本质，就是在这个映射空间里面，找到最佳的映射，使得映射之后的结果向量与目标向量，差别最小